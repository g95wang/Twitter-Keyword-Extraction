{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7KNY4WEGjP3"
      },
      "source": [
        "# !pip install git+https://github.com/howl-anderson/tf_crf_layer.git\\\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQlJnOuBFcEK"
      },
      "source": [
        "from copy import deepcopy\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Activation, Flatten, Input, Concatenate\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import tensorflow_addons as tfa \n",
        "# from tf_crf_layer.layer import CRF\n",
        "# from tf_crf_layer.loss import crf_loss\n",
        "# from tf_crf_layer.metrics import crf_accuracy\n",
        "# from tf_crf_layer.crf_static_constraint_helper import allowed_transitions"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG-y5i499Qnu"
      },
      "source": [
        "threshold = 0.2\n",
        "hidden_size = 100\n",
        "word_embedding_dim = 300\n",
        "class_labels_number = 5\n",
        "num_text = 5\n",
        "\n",
        "labeled_dataset_size = 1830\n",
        "train_dataset_size = 900\n",
        "validation_dataset_size = 100\n",
        "test_dataset_size = 830\n",
        "unlabeled_dataset_size = 0\n",
        "\n",
        "pos_list = np.char.lower([\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CONJ\",\"DET\",\"INTJ\",\"NOUN\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"VERB\",\"X\"])\n",
        "dep_list = np.char.lower([\"ROOT\", \"acl\", \"acomp\", \"advcl\", \"advmod\", \"agent\", \"amod\", \"appos\", \"attr\", \"aux\", \"auxpass\", \"case\", \"cc\", \"ccomp\", \"compound\", \"conj\", \"csubj\", \"csubjpass\", \"dative\", \"dep\", \"det\", \"dobj\", \"expl\", \"intj\", \"mark\", \"meta\", \"neg\", \"nmod\", \"npadvmod\", \"nsubj\", \"nsubjpass\", \"nummod\", \"oprd\", \"parataxis\", \"pcomp\", \"pobj\", \"poss\", \"preconj\", \"predet\", \"prep\", \"prt\", \"punct\", \"quantmod\", \"relcl\", \"xcomp\"])\n",
        "\n",
        "pos_dim = len(pos_list)\n",
        "dep_dim = len(dep_list)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71AmTAhcjUE7"
      },
      "source": [
        "def one_hot(vec, dic):\n",
        "    vec = np.char.lower(vec)\n",
        "    return np.array([dic == row for row in vec], dtype='i1')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD_hXorkv6SE"
      },
      "source": [
        "labeled_dataset = []\n",
        "unlabeled_dataset = []\n",
        "\n",
        "train_dataset = []\n",
        "validation_dataset = []\n",
        "test_dataset = []\n",
        "\n",
        "for i in range(1, labeled_dataset_size + 1):\n",
        "    filename = \"processed-labeled-tweet-{}.csv\".format(i)\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, newline='') as csvfile:\n",
        "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "            data = [tuple(x) for x in spamreader]\n",
        "            data = np.array(data, dtype=([(\"text\", 'U20'),(\"simplified_text\", 'U20'), (\"best_match\", 'U20'), (\"index\", int), (\"pos\", 'U20'), (\"dep\", 'U20'), (\"stop\", 'U5'), (\"label\", 'i1')]))\n",
        "            labeled_dataset.append(data)\n",
        "\n",
        "\n",
        "for i in range(len(labeled_dataset)):\n",
        "    tweet = labeled_dataset[i]\n",
        "    text = tf.reshape(tweet[\"index\"], (1, -1, 1))\n",
        "    pos = tf.reshape(one_hot(tweet[\"pos\"], pos_list), (1, -1, pos_dim))\n",
        "    dep = tf.reshape(one_hot(tweet[\"dep\"], dep_list), (1, -1, dep_dim))\n",
        "    label = tf.reshape(tf.one_hot(tweet[\"label\"], 2), (1, -1, 2))\n",
        "    train_dataset.append((np.concatenate((text, pos, dep), axis=-1), label))\n",
        "\n",
        "validation_dataset = train_dataset[901:1001]\n",
        "test_dataset = train_dataset[1001:]\n",
        "train_dataset = train_dataset[:901]\n",
        "\n",
        "# for i in range(1, 5):\n",
        "#     filename = \"processed-tweet-{}.csv\".format(i)\n",
        "#     with open(filename, newline='') as csvfile:\n",
        "#         spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "#         unlabeled_dataset.append(np.array(list(spamreader)))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zafkheWi_UUW",
        "outputId": "1d6493ce-88d3-41e8-d4d8-b53e75d94298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# tag_decoded_labels = {0:\"B\", 1:\"I\", 2:\"O\", 3:\"U\", 4:\"L\"}\n",
        "# constraints = allowed_transitions(\"BIOUL\", tag_decoded_labels)\n",
        "\n",
        "inputs = Input(shape=(None, pos_dim+dep_dim+1))\n",
        "x = Embedding(380000, word_embedding_dim)(inputs[:,:,0])\n",
        "x = Concatenate(axis=-1)([inputs[:,:,1:], x])\n",
        "x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "outputs = Dense(2, activation=tf.nn.sigmoid)(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(380000, word_embedding_dim, input_shape=(None,)))\n",
        "# model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "# model.add(Dense(2))\n",
        "# model.add(Activation('sigmoid'))\n",
        "# TODO: add constraints to CRF layer\n",
        "# model.add(CRF(class_labels_number))\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False\n",
        ")\n",
        "# model.compile(loss=BinaryCrossentropy(), optimizer=opt)\n",
        "model.compile(loss=BinaryCrossentropy(),metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()], optimizer=opt)\n",
        "# model.fit(np.array([[0,1], [3,2]]), np.array([[[0,1], [1,0]], [[1,0], [1,0]]]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None, 63)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_4 (Te [(None, None)]       0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_5 (Te [(None, None, 62)]   0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 300)    114000000   tf_op_layer_strided_slice_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, 362)    0           tf_op_layer_strided_slice_5[0][0]\n",
            "                                                                 embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, None, 200)    370400      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 2)      402         bidirectional_2[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 114,370,802\n",
            "Trainable params: 114,370,802\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8VxMkhVcNfY"
      },
      "source": [
        "# for i in range(1, 5):\n",
        "#   filename = \"processed-labeled-tweet-{}.csv\".format(i)\n",
        "#   with open(filename, newline='') as csvfile:\n",
        "#       spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "#       processed_text = np.array(list(spamreader))\n",
        "#   labels = np.array(processed_text[:,-1], dtype=float)\n",
        "#   print(tf.reshape(tf.one_hot(labels, 2), (-1, 1, 2)))\n",
        "#   c = tf.one_hot(labels, 2)\n",
        "#   model.fit(np.array([0,1,100,3,1,4,2,4,1,5]), tf.reshape(tf.one_hot(labels, 2), (-1, 1, 2)))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76m7j_lxddr"
      },
      "source": [
        "def train_step(tweet):\n",
        "    x,y = tweet[0], tweet[1]\n",
        "    model.fit(x, y)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lryr-avIH-mC"
      },
      "source": [
        "def eval_step(tweet):\n",
        "    x,y = tweet[0], tweet[1]\n",
        "    # model.evaluate(np.array([0,1,100,3,1,4,2,4,1,5]), tf.reshape(tf.one_hot(labels, 2), (-1, 1, 2)))\n",
        "    return model.evaluate(x, y)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAtJMaJ6XOWo"
      },
      "source": [
        "def predict_step(tweet):\n",
        "    return model.predict(tweet)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OB2W1W7dAi6"
      },
      "source": [
        "def neg_log(prediction):\n",
        "    return -np.mean(np.log(np.amax(prediction, axis=-1)))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjV4QhB9urAJ"
      },
      "source": [
        "def semi_supervised():\n",
        "    for tweet in train_dataset:\n",
        "        train_step(tweet)\n",
        "    for tweet in validation_dataset:\n",
        "        eval_step(tweet)\n",
        "    for tweet in unlabeled_dataset:\n",
        "        prediction = predict_step(tweet)\n",
        "        if neg_log(prediction) < threshold:\n",
        "            print(\"here\")\n",
        "            # label = \n",
        "    # for tweet in validation_dataset:\n",
        "    #     eval_step(tweet)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk74kr-28h6D",
        "outputId": "bb89fd7c-5451-454a-81a8-3085f9b1bafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "semi_supervised()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6908 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6771 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - precision_2: 0.4800 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7331 - precision_2: 0.2500 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6673 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7189 - precision_2: 0.2500 - recall_2: 0.2000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7011 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5768 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6627 - precision_2: 0.5833 - recall_2: 0.5833\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8215 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6832 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7331 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8800 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6032 - precision_2: 0.4500 - recall_2: 0.4500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8099 - precision_2: 0.5385 - recall_2: 0.5385\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6519 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7719 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6007 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - precision_2: 0.5000 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6362 - precision_2: 0.6875 - recall_2: 0.6471\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5976 - precision_2: 0.7222 - recall_2: 0.6842\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6178 - precision_2: 0.6000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6654 - precision_2: 0.7000 - recall_2: 0.5385\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5343 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5860 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5226 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7675 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4918 - precision_2: 0.8667 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8521 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8370 - precision_2: 0.3125 - recall_2: 0.3125\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6719 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4861 - precision_2: 0.8000 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7156 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4289 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5660 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5636 - precision_2: 0.7059 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3357 - precision_2: 0.8947 - recall_2: 0.8947\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5637 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4802 - precision_2: 0.7778 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9455 - precision_2: 0.2500 - recall_2: 0.2500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4749 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - precision_2: 0.8000 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5185 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3937 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4428 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3612 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5219 - precision_2: 0.6667 - recall_2: 0.5455\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6346 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0933 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7277 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3125 - precision_2: 0.9375 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4614 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4268 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3795 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2814 - precision_2: 0.8824 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5161 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3455 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2272 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8190 - precision_2: 0.5294 - recall_2: 0.5625\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7715 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2855 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3995 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9687 - precision_2: 0.5909 - recall_2: 0.5909\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3311 - precision_2: 0.8571 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2032 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8420 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4130 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8876 - precision_2: 0.5000 - recall_2: 0.5556\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3280 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2020 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7851 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5796 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2291 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4300 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6717 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4886 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4186 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6430 - precision_2: 0.6842 - recall_2: 0.6842\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5697 - precision_2: 0.6429 - recall_2: 0.6429\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3859 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4410 - precision_2: 1.0000 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3943 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3303 - precision_2: 0.8462 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4005 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3510 - precision_2: 0.9091 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3248 - precision_2: 0.8333 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4327 - precision_2: 0.7727 - recall_2: 0.7391\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4941 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1031 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4441 - precision_2: 0.6364 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3589 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7620 - precision_2: 0.6316 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3186 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6352 - precision_2: 0.7619 - recall_2: 0.7619\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8775 - precision_2: 0.5556 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3243 - precision_2: 0.7308 - recall_2: 0.7308\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1849 - precision_2: 0.6667 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0265 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8124 - precision_2: 0.2500 - recall_2: 0.2500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5776 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3983 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6520 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8254 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - precision_2: 0.8947 - recall_2: 0.8947\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9971 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4915 - precision_2: 0.7200 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3781 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6659 - precision_2: 0.6667 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5944 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6323 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3750 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4429 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4200 - precision_2: 0.9000 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7497 - precision_2: 0.4118 - recall_2: 0.4118\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5008 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4459 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5104 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - precision_2: 0.6923 - recall_2: 0.7200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6992 - precision_2: 0.6250 - recall_2: 0.5882\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3212 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6274 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4012 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6972 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0688 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9813 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5762 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4150 - precision_2: 0.8182 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3823 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4476 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9590 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3139 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4847 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3401 - precision_2: 0.8462 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1216 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4174 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6805 - precision_2: 0.5000 - recall_2: 0.5385\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3718 - precision_2: 0.9333 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3108 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7183 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4413 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4320 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1866 - precision_2: 0.2500 - recall_2: 0.2500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3979 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5065 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8292 - precision_2: 0.6364 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3728 - precision_2: 0.9444 - recall_2: 0.9444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7153 - precision_2: 0.5500 - recall_2: 0.5789\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5044 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8515 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7508 - precision_2: 0.5882 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3367 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3652 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5643 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4206 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3777 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2162 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7554 - precision_2: 0.5500 - recall_2: 0.5238\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5564 - precision_2: 0.7059 - recall_2: 0.7059\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - precision_2: 0.8235 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3504 - precision_2: 0.8182 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5712 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4738 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3068 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6614 - precision_2: 0.4000 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2835 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6005 - precision_2: 0.6875 - recall_2: 0.6471\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8056 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7633 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5147 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7935 - precision_2: 0.5833 - recall_2: 0.5833\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5159 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5420 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5863 - precision_2: 0.7273 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5152 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6508 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6634 - precision_2: 0.6000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7447 - precision_2: 0.4545 - recall_2: 0.4762\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6588 - precision_2: 0.5556 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7482 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5718 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8623 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5327 - precision_2: 0.6364 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5081 - precision_2: 0.8182 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6833 - precision_2: 0.7857 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4204 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6170 - precision_2: 0.7391 - recall_2: 0.7391\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8829 - precision_2: 0.5556 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6833 - precision_2: 0.5294 - recall_2: 0.5294\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3994 - precision_2: 0.8750 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7216 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2507 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - precision_2: 0.8750 - recall_2: 0.7368\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6444 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5110 - precision_2: 0.8571 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6213 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3285 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3787 - precision_2: 0.7727 - recall_2: 0.7727\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3646 - precision_2: 0.8636 - recall_2: 0.8636\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5644 - precision_2: 0.7500 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4086 - precision_2: 0.8800 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9596 - precision_2: 0.3571 - recall_2: 0.3571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - precision_2: 0.4444 - recall_2: 0.4444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2162 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1802 - precision_2: 0.9583 - recall_2: 0.9583\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6427 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3933 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4457 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4048 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0036 - precision_2: 0.4667 - recall_2: 0.4667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5254 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5219 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5822 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2961 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6270 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6126 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2116 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4055 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5946 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1466 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7969 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6555 - precision_2: 0.7308 - recall_2: 0.7600\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6765 - precision_2: 0.5000 - recall_2: 0.4706\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6610 - precision_2: 0.6667 - recall_2: 0.6957\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6379 - precision_2: 0.7143 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4713 - precision_2: 0.8462 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8606 - precision_2: 0.5833 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3770 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8629 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1876 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5500 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2226 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8272 - precision_2: 0.4444 - recall_2: 0.4444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5290 - precision_2: 0.8462 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8524 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6010 - precision_2: 0.7083 - recall_2: 0.6800\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4727 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2798 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4385 - precision_2: 0.7391 - recall_2: 0.7083\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4361 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2740 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5412 - precision_2: 0.6667 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5045 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4387 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5899 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7107 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5737 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5938 - precision_2: 0.7059 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6138 - precision_2: 0.5556 - recall_2: 0.5556\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7275 - precision_2: 0.4167 - recall_2: 0.4545\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7064 - precision_2: 0.6471 - recall_2: 0.6471\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7689 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1397 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3332 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4264 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5640 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6321 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4148 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4032 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5838 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3035 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4971 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5364 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8841 - precision_2: 0.5625 - recall_2: 0.5625\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6227 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4437 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5660 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5118 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2478 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7479 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5609 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4599 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2205 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7502 - precision_2: 0.2500 - recall_2: 0.2500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5718 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3328 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7092 - precision_2: 0.5385 - recall_2: 0.5385\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4983 - precision_2: 0.7857 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3743 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4550 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3476 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4536 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3483 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4550 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4407 - precision_2: 0.7778 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6131 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9015 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2054 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5169 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9191 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8056 - precision_2: 0.4444 - recall_2: 0.4444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5885 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4847 - precision_2: 0.7222 - recall_2: 0.6842\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6610 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6199 - precision_2: 0.6154 - recall_2: 0.6154\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3705 - precision_2: 0.8750 - recall_2: 0.9333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4458 - precision_2: 0.7692 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5632 - precision_2: 0.5833 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6767 - precision_2: 0.6364 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5223 - precision_2: 0.7222 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6625 - precision_2: 0.7059 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4710 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - precision_2: 0.6875 - recall_2: 0.6875\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - precision_2: 0.8095 - recall_2: 0.8095\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4108 - precision_2: 0.8000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4548 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3829 - precision_2: 0.8824 - recall_2: 0.9375\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3300 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3528 - precision_2: 0.9333 - recall_2: 0.9333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8162 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5082 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2941 - precision_2: 0.9091 - recall_2: 0.9524\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3570 - precision_2: 0.8182 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3920 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4252 - precision_2: 0.7826 - recall_2: 0.7826\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5221 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2871 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4703 - precision_2: 0.7826 - recall_2: 0.7826\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9163 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5148 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4280 - precision_2: 0.7500 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3088 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1864 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9892 - precision_2: 0.6111 - recall_2: 0.6111\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4272 - precision_2: 0.8824 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4271 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3260 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6771 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4743 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4059 - precision_2: 0.8125 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2355 - precision_2: 1.0000 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5409 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1603 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1944 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3530 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1440 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9002 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5206 - precision_2: 0.8824 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2981 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7285 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8321 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5070 - precision_2: 0.7917 - recall_2: 0.7917\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5801 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1213 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5008 - precision_2: 0.7727 - recall_2: 0.7727\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5985 - precision_2: 0.7500 - recall_2: 0.7895\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4332 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5897 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3804 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4253 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8305 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2581 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6491 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4001 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4009 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6178 - precision_2: 1.0000 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3520 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2219 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4172 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1759 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5152 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6222 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5886 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4209 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5412 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3997 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5332 - precision_2: 0.6667 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1287 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3603 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8973 - precision_2: 0.6000 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1524 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1275 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2020 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0722 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5725 - precision_2: 0.7308 - recall_2: 0.7917\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2133 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7747 - precision_2: 0.5556 - recall_2: 0.5882\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6416 - precision_2: 0.7895 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1162 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6363 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7113 - precision_2: 0.6364 - recall_2: 0.5833\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5868 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5368 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1691 - precision_2: 1.0000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6278 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1923 - precision_2: 0.8667 - recall_2: 0.8667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9947 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2772 - precision_2: 0.8421 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2390 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2311 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4434 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3929 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1991 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5254 - precision_2: 0.7619 - recall_2: 0.7619\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6269 - precision_2: 0.6923 - recall_2: 0.7200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2674 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7383 - precision_2: 0.6429 - recall_2: 0.6429\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2605 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6359 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4444 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7747 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3953 - precision_2: 0.8000 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9479 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2182 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3135 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2837 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4229 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6818 - precision_2: 0.6364 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4676 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8880 - precision_2: 0.4286 - recall_2: 0.4286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5455 - precision_2: 0.7500 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2461 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3929 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2846 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4197 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4153 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3949 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3984 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7472 - precision_2: 0.5909 - recall_2: 0.5909\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6810 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6566 - precision_2: 0.7500 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8202 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5425 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3622 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4208 - precision_2: 0.7857 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3025 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6513 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8349 - precision_2: 0.4545 - recall_2: 0.4545\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5895 - precision_2: 0.6316 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3518 - precision_2: 0.9444 - recall_2: 0.8947\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2611 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3864 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5380 - precision_2: 0.6875 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4540 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4383 - precision_2: 0.7500 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4955 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4464 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2549 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3067 - precision_2: 0.8889 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4430 - precision_2: 0.7500 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8039 - precision_2: 0.5294 - recall_2: 0.5294\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3726 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2901 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5161 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5364 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3746 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1877 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3743 - precision_2: 0.7857 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4250 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6331 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5612 - precision_2: 0.6957 - recall_2: 0.6957\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3824 - precision_2: 0.7692 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5121 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4675 - precision_2: 0.6667 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1166 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3344 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2842 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2899 - precision_2: 0.8421 - recall_2: 0.8421\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4718 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6129 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1252 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5384 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5662 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7132 - precision_2: 0.7083 - recall_2: 0.7391\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4036 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7931 - precision_2: 0.6111 - recall_2: 0.6111\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6556 - precision_2: 0.7059 - recall_2: 0.7059\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3893 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1203 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2341 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2253 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7456 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2912 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6263 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6522 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1351 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3635 - precision_2: 0.7812 - recall_2: 0.7812\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2769 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3270 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2785 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4845 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3852 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2518 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7355 - precision_2: 0.6364 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5915 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7296 - precision_2: 0.5789 - recall_2: 0.6111\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1817 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2578 - precision_2: 0.9375 - recall_2: 0.9375\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5739 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2567 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4046 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1888 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0751 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3813 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6346 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3215 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4520 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5363 - precision_2: 0.7222 - recall_2: 0.7222\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4325 - precision_2: 0.7750 - recall_2: 0.7750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1492 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7089 - precision_2: 0.5926 - recall_2: 0.6154\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1830 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6195 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4611 - precision_2: 0.8235 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4437 - precision_2: 0.7895 - recall_2: 0.7895\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4565 - precision_2: 0.7826 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7991 - precision_2: 0.6316 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0174 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4870 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5182 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2816 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9346 - precision_2: 0.5625 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1744 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8139 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2253 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3037 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2502 - precision_2: 0.9375 - recall_2: 0.9375\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9031 - precision_2: 0.5652 - recall_2: 0.5909\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6859 - precision_2: 0.6667 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4436 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3325 - precision_2: 0.8654 - recall_2: 0.8654\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7890 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2857 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2938 - precision_2: 0.9444 - recall_2: 0.9444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1843 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7928 - precision_2: 0.5625 - recall_2: 0.5625\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2994 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5102 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2817 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6003 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6309 - precision_2: 0.6875 - recall_2: 0.6875\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4820 - precision_2: 0.8333 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1045 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7911 - precision_2: 0.6154 - recall_2: 0.6154\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6814 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5625 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4343 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5892 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8037 - precision_2: 0.6364 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3132 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3603 - precision_2: 0.8333 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3674 - precision_2: 0.9444 - recall_2: 0.9444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5862 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6953 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4261 - precision_2: 0.8421 - recall_2: 0.8421\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4544 - precision_2: 0.8235 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1835 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3577 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7786 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5244 - precision_2: 0.5000 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3648 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4716 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4580 - precision_2: 0.7895 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4009 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3248 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6690 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3302 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3413 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - precision_2: 0.8125 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6184 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2137 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9726 - precision_2: 0.5625 - recall_2: 0.5294\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3485 - precision_2: 0.8824 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8578 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4466 - precision_2: 0.8000 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6780 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4332 - precision_2: 0.8462 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2971 - precision_2: 0.8824 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0317 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3895 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2060 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2798 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7192 - precision_2: 0.6429 - recall_2: 0.6429\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6637 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4206 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2243 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3939 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5163 - precision_2: 0.7333 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4188 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2173 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8230 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4128 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2822 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2870 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6780 - precision_2: 0.5263 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0996 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4557 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6254 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2365 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7024 - precision_2: 0.6364 - recall_2: 0.6364\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3898 - precision_2: 0.7895 - recall_2: 0.7895\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2966 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7900 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4734 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - precision_2: 0.7727 - recall_2: 0.7727\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2351 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2657 - precision_2: 0.9412 - recall_2: 0.9412\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6528 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3534 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - precision_2: 0.8125 - recall_2: 0.8125\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2138 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6421 - precision_2: 0.5789 - recall_2: 0.5789\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3496 - precision_2: 0.2500 - recall_2: 0.2500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0712 - precision_2: 0.4000 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6798 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3502 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4336 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3443 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6179 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3518 - precision_2: 0.9412 - recall_2: 0.9412\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3504 - precision_2: 0.8462 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5970 - precision_2: 0.7143 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5602 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1987 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5132 - precision_2: 0.6250 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3370 - precision_2: 0.8182 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4350 - precision_2: 0.7368 - recall_2: 0.7368\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7696 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4973 - precision_2: 0.7500 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5368 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4398 - precision_2: 0.6522 - recall_2: 0.6818\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4439 - precision_2: 0.7500 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4944 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4031 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1811 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3212 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5918 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4939 - precision_2: 0.7500 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6652 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2935 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3595 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4946 - precision_2: 0.8462 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3243 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5007 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7458 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2970 - precision_2: 0.8571 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3451 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1498 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0585 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7755 - precision_2: 0.6875 - recall_2: 0.6471\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4943 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7262 - precision_2: 0.6111 - recall_2: 0.6111\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4057 - precision_2: 0.8000 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2670 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7073 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3446 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5299 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9113 - precision_2: 0.5789 - recall_2: 0.5789\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5071 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5403 - precision_2: 0.6316 - recall_2: 0.6316\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1291 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5788 - precision_2: 0.5625 - recall_2: 0.5625\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4288 - precision_2: 0.7200 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3643 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6244 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4232 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6806 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3301 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2605 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5125 - precision_2: 0.6111 - recall_2: 0.6111\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5240 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3229 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8635 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2834 - precision_2: 0.8462 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6806 - precision_2: 0.7059 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4049 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0651 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - precision_2: 0.8125 - recall_2: 0.8125\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2494 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5551 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4858 - precision_2: 0.8421 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4959 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3760 - precision_2: 1.0000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5478 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4524 - precision_2: 0.6875 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2229 - precision_2: 0.9500 - recall_2: 0.9048\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2189 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3944 - precision_2: 0.7222 - recall_2: 0.7222\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3559 - precision_2: 0.8947 - recall_2: 0.8947\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2574 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5293 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1746 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2069 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5509 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8964 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1112 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3728 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5092 - precision_2: 0.8333 - recall_2: 0.7895\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6459 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8240 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0080 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3977 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3166 - precision_2: 0.7895 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5022 - precision_2: 0.7391 - recall_2: 0.7727\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5286 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6600 - precision_2: 0.7059 - recall_2: 0.7059\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2828 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1667 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2801 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9573 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2249 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1307 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6601 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4252 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2779 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2352 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3673 - precision_2: 0.9091 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3434 - precision_2: 1.0000 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4039 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4793 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3470 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3349 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3864 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7710 - precision_2: 0.5000 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2424 - precision_2: 0.8636 - recall_2: 0.8636\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4395 - precision_2: 0.7500 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5751 - precision_2: 0.7826 - recall_2: 0.7826\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2104 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6583 - precision_2: 0.5882 - recall_2: 0.5882\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4563 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2661 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1142 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6972 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1541 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1953 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1841 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3326 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1995 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6236 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5836 - precision_2: 0.7368 - recall_2: 0.7368\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5043 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3505 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2770 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3148 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3780 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7401 - precision_2: 0.5263 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3294 - precision_2: 0.8421 - recall_2: 0.8421\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3691 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5571 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3752 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4655 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2069 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4343 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2080 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6726 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5163 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5638 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4231 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7781 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6987 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6561 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3969 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3909 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6304 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0462 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6758 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2217 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9361 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4698 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2293 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1245 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5530 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1815 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3758 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5771 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4151 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3390 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3908 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5023 - precision_2: 0.7273 - recall_2: 0.7619\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7750 - precision_2: 0.5294 - recall_2: 0.5294\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - precision_2: 0.7500 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9530 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4075 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5353 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3004 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5886 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3866 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4941 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1428 - precision_2: 0.2500 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3866 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2094 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4562 - precision_2: 0.6923 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7260 - precision_2: 0.5333 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3193 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2674 - precision_2: 0.9444 - recall_2: 0.9444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0146 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3179 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3617 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5267 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6324 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6120 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3318 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2123 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2159 - precision_2: 0.9333 - recall_2: 0.9333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1506 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2147 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4094 - precision_2: 0.8182 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7137 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3018 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7284 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3877 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3545 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4076 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3313 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3789 - precision_2: 0.9333 - recall_2: 0.9333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4206 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8786 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0949 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8420 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7443 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3806 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2983 - precision_2: 0.9333 - recall_2: 0.9333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4400 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2808 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1354 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5250 - precision_2: 0.7143 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1376 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6329 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1770 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4281 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - precision_2: 0.8750 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6508 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0390 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4606 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3714 - precision_2: 1.0000 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7962 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1011 - precision_2: 0.2500 - recall_2: 0.2500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4732 - precision_2: 0.8824 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4905 - precision_2: 0.6429 - recall_2: 0.6429\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5774 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3432 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4095 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1997 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6871 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5011 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6368 - precision_2: 0.6250 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6176 - precision_2: 0.7059 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4746 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6770 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8325 - precision_2: 0.4444 - recall_2: 0.4444\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6876 - precision_2: 0.6111 - recall_2: 0.6111\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4145 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4572 - precision_2: 0.7692 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6576 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2350 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5991 - precision_2: 0.6667 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2384 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5757 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5098 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9371 - precision_2: 0.3000 - recall_2: 0.3000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2511 - precision_2: 0.9412 - recall_2: 0.9412\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6276 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3046 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4039 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6543 - precision_2: 0.6154 - recall_2: 0.6154\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6675 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3887 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6176 - precision_2: 0.7368 - recall_2: 0.7368\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8661 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2714 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5050 - precision_2: 0.7222 - recall_2: 0.7222\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8094 - precision_2: 0.6111 - recall_2: 0.6111\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2076 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - precision_2: 0.8750 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1587 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5013 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1672 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - precision_2: 0.8333 - recall_2: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHVKcBMKZ6a-",
        "outputId": "7afd3e96-4df6-410e-8963-a2b7c97b1d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sum = 0\n",
        "p,r=0,0\n",
        "for tweet in test_dataset:\n",
        "    eval = eval_step(tweet)\n",
        "    precision, recall = eval[0], eval[1]\n",
        "    p+=precision\n",
        "    r+=recall\n",
        "print(p/len(test_dataset))\n",
        "print(r/len(test_dataset))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2162 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1779 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5325 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3645 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5936 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5973 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3951 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6447 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2075 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3923 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5482 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2395 - precision_2: 0.9286 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7048 - precision_2: 0.6154 - recall_2: 0.6154\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2082 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7632 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2872 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - precision_2: 0.7500 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1316 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1112 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3057 - precision_2: 0.8421 - recall_2: 0.8421\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7195 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6720 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5432 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2610 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2443 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3433 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8869 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3454 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4427 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3760 - precision_2: 0.8125 - recall_2: 0.8125\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5250 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3438 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9908 - precision_2: 0.4286 - recall_2: 0.4286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1833 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5160 - precision_2: 0.7727 - recall_2: 0.7727\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6829 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5563 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7467 - precision_2: 0.5455 - recall_2: 0.5455\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1582 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4403 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6960 - precision_2: 0.6154 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1860 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5555 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4243 - precision_2: 0.8500 - recall_2: 0.8500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5217 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2992 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3040 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1775 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1656 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2361 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7664 - precision_2: 0.6000 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4502 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4003 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6083 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1826 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1401 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1957 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2753 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0477 - precision_2: 0.2857 - recall_2: 0.2857\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5792 - precision_2: 0.6471 - recall_2: 0.6875\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5601 - precision_2: 0.7500 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4444 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3882 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8114 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3518 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1092 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6864 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4953 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3955 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7815 - precision_2: 0.6500 - recall_2: 0.6500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1373 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2851 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5088 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3922 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4473 - precision_2: 0.7895 - recall_2: 0.7895\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4448 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7859 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5702 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3716 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3026 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4428 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5328 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5099 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1962 - precision_2: 0.9444 - recall_2: 0.9444\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4820 - precision_2: 0.7619 - recall_2: 0.7619\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3728 - precision_2: 0.8333 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5126 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1649 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4346 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5725 - precision_2: 0.6957 - recall_2: 0.6957\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0478 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6502 - precision_2: 0.6154 - recall_2: 0.6154\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5356 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2220 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6637 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5233 - precision_2: 0.7143 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2184 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1586 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1325 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4820 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3182 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4095 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4471 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4251 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8109 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2647 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6082 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5183 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3144 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5103 - precision_2: 0.7647 - recall_2: 0.8125\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6169 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1165 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4909 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4457 - precision_2: 0.7143 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2935 - precision_2: 1.0000 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2130 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3111 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7745 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3813 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5734 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6218 - precision_2: 0.6000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3033 - precision_2: 0.9091 - recall_2: 0.9091\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8014 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1135 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4047 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8484 - precision_2: 0.5556 - recall_2: 0.5556\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5135 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6871 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1219 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4410 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5452 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6410 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6189 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6530 - precision_2: 0.6875 - recall_2: 0.6875\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4405 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3260 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5535 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6559 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4677 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5996 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2085 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8662 - precision_2: 0.5263 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5849 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5421 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4191 - precision_2: 0.8235 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2926 - precision_2: 0.9444 - recall_2: 0.9444\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2513 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6023 - precision_2: 0.6471 - recall_2: 0.6471\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - precision_2: 0.7000 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3059 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3757 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5683 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4045 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4319 - precision_2: 0.7647 - recall_2: 0.7647\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3057 - precision_2: 0.9375 - recall_2: 0.9375\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6060 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2389 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4967 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5480 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4169 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3527 - precision_2: 0.8462 - recall_2: 0.8462\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0659 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2776 - precision_2: 0.8824 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6154 - precision_2: 0.6296 - recall_2: 0.6296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3323 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3876 - precision_2: 0.8095 - recall_2: 0.8095\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4811 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2335 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4074 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9544 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3196 - precision_2: 0.9167 - recall_2: 0.9167\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7993 - precision_2: 0.6154 - recall_2: 0.6154\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3276 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2516 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1686 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5354 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0132 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2877 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6889 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0524 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5040 - precision_2: 0.6500 - recall_2: 0.6500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5724 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2768 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7642 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6648 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4883 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3652 - precision_2: 0.7857 - recall_2: 0.7857\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7976 - precision_2: 0.5238 - recall_2: 0.5238\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1332 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8018 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8611 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5748 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5033 - precision_2: 0.7692 - recall_2: 0.7692\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4834 - precision_2: 0.7368 - recall_2: 0.7368\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3409 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2960 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8292 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2721 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5479 - precision_2: 0.6842 - recall_2: 0.6842\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3759 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3227 - precision_2: 0.7895 - recall_2: 0.7895\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5465 - precision_2: 0.7826 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5362 - precision_2: 0.7368 - recall_2: 0.7368\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3001 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7068 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5367 - precision_2: 0.7222 - recall_2: 0.7222\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7476 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4758 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5125 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3096 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4508 - precision_2: 0.8125 - recall_2: 0.8125\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8192 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7173 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3811 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3643 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5992 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3952 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6111 - precision_2: 0.6818 - recall_2: 0.6522\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7447 - precision_2: 0.7222 - recall_2: 0.7222\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1071 - precision_2: 0.3333 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3452 - precision_2: 0.7895 - recall_2: 0.7895\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4159 - precision_2: 0.8261 - recall_2: 0.8261\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - precision_2: 0.8182 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5882 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6044 - precision_2: 0.7222 - recall_2: 0.7222\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3187 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3700 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3132 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7631 - precision_2: 0.6316 - recall_2: 0.6316\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5729 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6460 - precision_2: 0.7368 - recall_2: 0.7368\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4690 - precision_2: 0.7500 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3295 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2616 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4189 - precision_2: 0.7143 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6620 - precision_2: 0.6875 - recall_2: 0.6875\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2867 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3989 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4931 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1229 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3766 - precision_2: 0.8696 - recall_2: 0.8696\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7475 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5300 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5155 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4116 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2794 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5906 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3542 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4025 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3103 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6724 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8248 - precision_2: 0.7000 - recall_2: 0.7000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2797 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5378 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4271 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3141 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5057 - precision_2: 0.7333 - recall_2: 0.7333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1996 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6438 - precision_2: 0.6250 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5071 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8545 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4769 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6542 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3034 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5168 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9083 - precision_2: 0.5556 - recall_2: 0.5556\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8480 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2520 - precision_2: 0.3333 - recall_2: 0.3333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3853 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4141 - precision_2: 0.8235 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4549 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7195 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4770 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8003 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5997 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5727 - precision_2: 0.6000 - recall_2: 0.6000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6746 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5697 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2809 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9320 - precision_2: 0.4000 - recall_2: 0.4000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5924 - precision_2: 0.6923 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7825 - precision_2: 0.4615 - recall_2: 0.4615\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2391 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5515 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3721 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7357 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3309 - precision_2: 0.9286 - recall_2: 0.9286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7726 - precision_2: 0.4444 - recall_2: 0.4444\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1042 - precision_2: 0.2500 - recall_2: 0.2500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7278 - precision_2: 0.6667 - recall_2: 0.6667\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4086 - precision_2: 0.8125 - recall_2: 0.8667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5824 - precision_2: 0.6923 - recall_2: 0.6923\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3961 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3961 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1294 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3616 - precision_2: 0.8333 - recall_2: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3598 - precision_2: 0.9231 - recall_2: 0.9231\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2920 - precision_2: 0.8824 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5125 - precision_2: 0.7500 - recall_2: 0.8182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8347 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5615 - precision_2: 0.8500 - recall_2: 0.8500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6139 - precision_2: 0.6667 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2437 - precision_2: 0.8750 - recall_2: 0.8750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7759 - precision_2: 0.5714 - recall_2: 0.5714\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3235 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5610 - precision_2: 0.8261 - recall_2: 0.8261\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5377 - precision_2: 0.7778 - recall_2: 0.8235\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9206 - precision_2: 0.3333 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5817 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4148 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2071 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1715 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8510 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6053 - precision_2: 0.6667 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2258 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1976 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6016 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7946 - precision_2: 0.3750 - recall_2: 0.3750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1638 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3034 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5827 - precision_2: 0.6471 - recall_2: 0.6875\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5831 - precision_2: 0.7727 - recall_2: 0.7391\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6233 - precision_2: 0.7222 - recall_2: 0.7222\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6414 - precision_2: 0.7273 - recall_2: 0.7273\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9699 - precision_2: 0.4615 - recall_2: 0.4615\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6558 - precision_2: 0.6471 - recall_2: 0.6471\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4247 - precision_2: 0.7143 - recall_2: 0.7143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7538 - precision_2: 0.5000 - recall_2: 0.5000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3432 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5749 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1602 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3528 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1173 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3158 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5064 - precision_2: 0.7778 - recall_2: 0.7778\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1436 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4953 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1475 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6999 - precision_2: 0.6250 - recall_2: 0.6250\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3810 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4166 - precision_2: 0.8824 - recall_2: 0.8824\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5770 - precision_2: 0.8000 - recall_2: 0.8000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2040 - precision_2: 0.8889 - recall_2: 0.8889\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2816 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2501 - precision_2: 0.9000 - recall_2: 0.9000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4552 - precision_2: 0.8571 - recall_2: 0.8571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4946 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6297 - precision_2: 0.7059 - recall_2: 0.7059\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3084 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5429 - precision_2: 0.7500 - recall_2: 0.7500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1982 - precision_2: 1.0000 - recall_2: 1.0000\n",
            "0.5083945582790131\n",
            "0.7677753240039403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cPouiaCo3dh",
        "outputId": "dd015b89-5521-43d4-c86b-9c45d22b5d87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "2/(1/0.508 + 1/0.768)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6115109717868339"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}