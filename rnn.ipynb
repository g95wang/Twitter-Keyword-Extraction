{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7KNY4WEGjP3"
      },
      "source": [
        "# !pip install git+https://github.com/howl-anderson/tf_crf_layer.git\\\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwlPUBQa0Zdg"
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile(\"processed-data-labeled.zip\",\"r\") as zip_ref:\n",
        "#     zip_ref.extractall(\"./\")\n",
        "# with zipfile.ZipFile(\"processed-data-unlabeled.zip\",\"r\") as zip_ref:\n",
        "#     zip_ref.extractall(\"./\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQlJnOuBFcEK"
      },
      "source": [
        "from copy import deepcopy\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Activation, Flatten, Input, Concatenate\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import tensorflow_addons as tfa \n",
        "import matplotlib.pyplot as plt\n",
        "# from tf_crf_layer.layer import CRF\n",
        "# from tf_crf_layer.loss import crf_loss\n",
        "# from tf_crf_layer.metrics import crf_accuracy\n",
        "# from tf_crf_layer.crf_static_constraint_helper import allowed_transitions"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG-y5i499Qnu"
      },
      "source": [
        "threshold = 0.1\n",
        "hidden_size = 100\n",
        "word_embedding_dim = 300\n",
        "class_labels_number = 5\n",
        "num_text = 5\n",
        "epochs = 5\n",
        "\n",
        "labeled_dataset_size = 1830\n",
        "train_dataset_size = 900\n",
        "validation_dataset_size = 100\n",
        "test_dataset_size = 830\n",
        "unlabeled_dataset_size = 4000\n",
        "\n",
        "pos_list = np.char.lower([\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CONJ\",\"DET\",\"INTJ\",\"NOUN\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"VERB\",\"X\"])\n",
        "dep_list = np.char.lower([\"ROOT\", \"acl\", \"acomp\", \"advcl\", \"advmod\", \"agent\", \"amod\", \"appos\", \"attr\", \"aux\", \"auxpass\", \"case\", \"cc\", \"ccomp\", \"compound\", \"conj\", \"csubj\", \"csubjpass\", \"dative\", \"dep\", \"det\", \"dobj\", \"expl\", \"intj\", \"mark\", \"meta\", \"neg\", \"nmod\", \"npadvmod\", \"nsubj\", \"nsubjpass\", \"nummod\", \"oprd\", \"parataxis\", \"pcomp\", \"pobj\", \"poss\", \"preconj\", \"predet\", \"prep\", \"prt\", \"punct\", \"quantmod\", \"relcl\", \"xcomp\"])\n",
        "\n",
        "pos_dim = len(pos_list)\n",
        "dep_dim = len(dep_list)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71AmTAhcjUE7"
      },
      "source": [
        "def one_hot(vec, dic):\n",
        "    vec = np.char.lower(vec)\n",
        "    return np.array([dic == row for row in vec], dtype='i1')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD_hXorkv6SE"
      },
      "source": [
        "labeled_dataset = []\n",
        "unlabeled_dataset = []\n",
        "\n",
        "train_dataset = []\n",
        "validation_dataset = []\n",
        "test_dataset = []\n",
        "ul_dataset = []\n",
        "\n",
        "for i in range(1, labeled_dataset_size + 1):\n",
        "    filename = \"processed-data-labeled/processed-labeled-tweet-{}.csv\".format(i)\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, newline='') as csvfile:\n",
        "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "            data = [tuple(x) for x in spamreader]\n",
        "            data = np.array(data, dtype=([(\"text\", 'U20'),(\"simplified_text\", 'U20'), (\"best_match\", 'U20'), (\"index\", int), (\"pos\", 'U20'), (\"dep\", 'U20'), (\"stop\", 'U5'), (\"label\", 'i1')]))\n",
        "            if len(data):\n",
        "                labeled_dataset.append(data)\n",
        "\n",
        "for i in range(len(labeled_dataset)):\n",
        "    tweet = labeled_dataset[i]\n",
        "    text = tf.reshape(tweet[\"index\"], (1, -1, 1))\n",
        "    pos = tf.reshape(one_hot(tweet[\"pos\"], pos_list), (1, -1, pos_dim))\n",
        "    dep = tf.reshape(one_hot(tweet[\"dep\"], dep_list), (1, -1, dep_dim))\n",
        "    label = tf.reshape(tf.one_hot(tweet[\"label\"], 2), (1, -1, 2))\n",
        "    train_dataset.append((np.concatenate((text, pos, dep), axis=-1), label))\n",
        "\n",
        "for i in range(1, unlabeled_dataset_size + 1):\n",
        "    filename = \"processed-data-unlabeled/processed-unlabeled-tweet-{}.csv\".format(i)\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, newline='') as csvfile:\n",
        "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "            data = [tuple(x) for x in spamreader]\n",
        "            data = np.array(data, dtype=([(\"text\", 'U20'),(\"simplified_text\", 'U20'), (\"best_match\", 'U20'), (\"index\", int), (\"pos\", 'U20'), (\"dep\", 'U20'), (\"stop\", 'U5')]))\n",
        "            if len(data):\n",
        "                unlabeled_dataset.append(data)\n",
        "\n",
        "for i in range(len(unlabeled_dataset)):\n",
        "    tweet = unlabeled_dataset[i]\n",
        "    text = tf.reshape(tweet[\"index\"], (1, -1, 1))\n",
        "    pos = tf.reshape(one_hot(tweet[\"pos\"], pos_list), (1, -1, pos_dim))\n",
        "    dep = tf.reshape(one_hot(tweet[\"dep\"], dep_list), (1, -1, dep_dim))\n",
        "    ul_dataset.append(np.concatenate((text, pos, dep), axis=-1))\n",
        "\n",
        "validation_dataset = train_dataset[901:1001]\n",
        "test_dataset = train_dataset[1001:1101]\n",
        "train_dataset = train_dataset[:9]\n",
        "\n",
        "used = np.zeros(len(ul_dataset))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zafkheWi_UUW",
        "outputId": "ffc84cd8-4bac-4da4-c331-dd1f1ab96787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = Input(shape=(None, pos_dim+dep_dim+1))\n",
        "x = Embedding(380000, word_embedding_dim)(inputs[:,:,0])\n",
        "x = Concatenate(axis=-1)([inputs[:,:,1:], x])\n",
        "x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "outputs = Dense(2, activation=tf.nn.sigmoid)(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False\n",
        ")\n",
        "model.compile(loss=BinaryCrossentropy(), optimizer=opt)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 63)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, None)]       0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, None, 62)]   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    114000000   tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, None, 362)    0           tf_op_layer_strided_slice_1[0][0]\n",
            "                                                                 embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, None, 200)    370400      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 2)      402         bidirectional[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 114,370,802\n",
            "Trainable params: 114,370,802\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1SnsNm1XIJz"
      },
      "source": [
        "def metrics(prediction, label):\n",
        "    prediction = (prediction > 0.5)[0,:,1]\n",
        "    label = label[0,:,1]\n",
        "    true_positive = np.sum(np.logical_and((prediction == label), (prediction == True)))\n",
        "    false_positive = np.sum(np.logical_and((prediction != label), (prediction == True)))\n",
        "    false_negative = np.sum(np.logical_and((prediction != label), (prediction == False)))\n",
        "    precision = 0 if true_positive == 0 else true_positive / (true_positive + false_positive)\n",
        "    recall = 0 if true_positive == 0 else true_positive / (true_positive + false_negative)\n",
        "    f1 = 0 if true_positive == 0 else 2 / (1 / precision + 1 / recall)\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76m7j_lxddr"
      },
      "source": [
        "def train_step(tweet):\n",
        "    x,y = tweet[0], tweet[1]\n",
        "    model.fit(x, y, verbose=0)\n",
        "    prediction = predict_step(x)\n",
        "    return metrics(prediction, y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lryr-avIH-mC"
      },
      "source": [
        "def eval_step(tweet):\n",
        "    x,y = tweet[0], tweet[1]\n",
        "    prediction = predict_step(x)\n",
        "    return metrics(prediction, y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAtJMaJ6XOWo"
      },
      "source": [
        "def predict_step(tweet):\n",
        "    return model.predict(tweet)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OB2W1W7dAi6"
      },
      "source": [
        "def neg_log(prediction):\n",
        "    return -np.mean(np.log(np.amax(prediction, axis=-1)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjV4QhB9urAJ"
      },
      "source": [
        "train_p, train_r, train_f = [], [], []\n",
        "val_p, val_r, val_f = [], [], []\n",
        "\n",
        "def semi_supervised():\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(\"Training epoch {}\".format(epoch+1))\n",
        "        count = 0\n",
        "        total = 0\n",
        "        precision, recall, f1 = 0, 0, 0\n",
        "        for tweet in train_dataset:\n",
        "            if count % 100 == 0:\n",
        "                print(\"Training iter {}\".format(count))\n",
        "            p, r, f = train_step(tweet)\n",
        "            total += tweet[0].shape[1]\n",
        "            precision += p * tweet[0].shape[1]\n",
        "            recall += r * tweet[0].shape[1]\n",
        "            f1 += f * tweet[0].shape[1]\n",
        "            count += 1\n",
        "        train_p.append(precision / total)\n",
        "        train_r.append(recall / total)\n",
        "        train_f.append(f1 / total)\n",
        "\n",
        "        print(\"Validation\")\n",
        "        total = 0\n",
        "        precision, recall, f1 = 0, 0, 0\n",
        "        for tweet in validation_dataset:\n",
        "            p, r, f = eval_step(tweet)\n",
        "            total += tweet[0].shape[1]\n",
        "            precision += p * tweet[0].shape[1]\n",
        "            recall += r * tweet[0].shape[1]\n",
        "            f1 += f * tweet[0].shape[1]\n",
        "\n",
        "        if len(val_f) == 0 or f1 / total > np.amax(val_f):\n",
        "            model.save_weights('./checkpoint')\n",
        "\n",
        "        val_p.append(precision / total)\n",
        "        val_r.append(recall / total)\n",
        "        val_f.append(f1 / total)\n",
        "\n",
        "        print(\"Enlarging training set\")\n",
        "        added = 0\n",
        "        for i in range(len(ul_dataset)):\n",
        "            tweet = ul_dataset[i]\n",
        "            if used[i] == False:\n",
        "                prediction = predict_step(tweet)\n",
        "                if neg_log(prediction) < threshold:\n",
        "                    label = prediction > 0.5\n",
        "                    train_dataset.append((tweet, label))\n",
        "                    used[i] = True\n",
        "                    added += 1\n",
        "        \n",
        "        print(\"Added {} data points to training set\".format(added))\n",
        "\n",
        "\n",
        "    model.load_weights('./checkpoint')\n",
        "    for tweet in test_dataset:\n",
        "        p, r, f = eval_step(tweet)\n",
        "        total += tweet[0].shape[1]\n",
        "        precision += p * tweet[0].shape[1]\n",
        "        recall += r * tweet[0].shape[1]\n",
        "        f1 += f * tweet[0].shape[1]\n",
        "    print(\"Test Dataset precision = {}, recall = {}, f1 = {}\".format(precision / total, recall / total, f1 / total))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk74kr-28h6D",
        "outputId": "b1ddaeca-60e5-474a-9d3b-cdd282024994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "semi_supervised()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n",
            "Training iter 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cb40d70365b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msemi_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-9936c845af85>\u001b[0m in \u001b[0;36msemi_supervised\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training iter {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprecision\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-04a2e4eb6ab8>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QAAaqh0Hywq"
      },
      "source": [
        "print(train_p, train_r, train_f)\n",
        "print(val_p, val_r, val_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIF_4MjNJL3W"
      },
      "source": [
        "# Plot training accuracy\n",
        "plt.plot(train_p)\n",
        "plt.plot(train_r)\n",
        "plt.plot(train_f)\n",
        "plt.title('training')\n",
        "plt.ylabel('score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend([\"precision\", \"recall\", \"f1\"], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot validation accuracy\n",
        "plt.plot(val_p)\n",
        "plt.plot(val_r)\n",
        "plt.plot(val_f)\n",
        "plt.title('validation')\n",
        "plt.ylabel('score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend([\"precision\", \"recall\", \"f1\"], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}